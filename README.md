# PageRank - Analyse de Performance PySpark

**Membres du groupe:** [VOTRE NOM 1, VOTRE NOM 2, VOTRE NOM 3]

## ğŸ“Š Objectif

Comparer les performances entre **PySpark DataFrame** et **PySpark RDD** pour le calcul du PageRank sur les donnÃ©es Wikipedia DBpedia.

## ğŸš€ DÃ©marrage Rapide

### Travail en Ã©quipe - ExÃ©cution parallÃ¨le

Chaque membre de l'Ã©quipe peut tester une configuration diffÃ©rente **en parallÃ¨le** sur son propre compte GCP :

```bash
# Membre 1 - Teste la configuration 2 workers
cd scripts
bash test_config_2workers.sh

# Membre 2 - Teste la configuration 4 workers  
cd scripts
bash test_config_4workers.sh

# Membre 3 - Teste la configuration 6 workers
cd scripts
bash test_config_6workers.sh
```

**Avantages :**
- âœ… **ExÃ©cution parallÃ¨le** : 3 personnes = 3x plus rapide
- âœ… **Scripts automatisÃ©s** : CrÃ©ation cluster â†’ Tests â†’ Suppression automatique
- âœ… **Budget optimisÃ©** : Clusters supprimÃ©s immÃ©diatement aprÃ¨s les tests
- âœ… **RÃ©sultats CSV** : GÃ©nÃ©ration automatique pour comparaison

### AgrÃ©gation des rÃ©sultats

Une fois que tous les membres ont terminÃ© leurs tests :

```bash
# Compiler tous les rÃ©sultats et gÃ©nÃ©rer les graphiques
cd scripts
bash compile_results.sh
```

Cela gÃ©nÃ¨re :
- ğŸ“Š Graphiques de comparaison PNG
- ğŸ“„ Fichier rÃ©capitulatif texte  
- ğŸ“ˆ Tableaux CSV consolidÃ©s

---

## ğŸ¯ RÃ©sultats Principaux

### ğŸ† EntitÃ© avec le plus grand PageRank

**Centre de Wikipedia:** `[Ã€ COMPLÃ‰TER APRÃˆS EXÃ‰CUTION]`

**PageRank:** `[Ã€ COMPLÃ‰TER]`

---

## ğŸ“ˆ Comparaison des Performances

### RÃ©sultats avec 10% des donnÃ©es

| Configuration | RDD (secondes) | DataFrame (secondes) | Gagnant | AmÃ©lioration |
|---------------|----------------|----------------------|---------|--------------|
| 2 nÅ“uds       | -              | -                    | -       | -            |
| 4 nÅ“uds       | -              | -                    | -       | -            |
| 6 nÅ“uds       | -              | -                    | -       | -            |

### RÃ©sultats avec 100% des donnÃ©es

| Configuration | RDD (secondes) | DataFrame (secondes) | Gagnant | AmÃ©lioration |
|---------------|----------------|----------------------|---------|--------------|
| 2 nÅ“uds       | -              | -                    | -       | -            |
| 4 nÅ“uds       | -              | -                    | -       | -            |
| 6 nÅ“uds       | -              | -                    | -       | -            |

---

## ğŸ› ï¸ Configuration MatÃ©rielle

- **Type de machine:** `e2-standard-4` (4 vCPU, 16 GB RAM) - SÃ©rie E2 Ã©conomique
- **RÃ©gion:** `europe-west1` (Belgique - optimise coÃ»ts et latence)
- **Machines prÃ©emptibles:** OUI âœ… (Ã©conomie de **80%** sur les coÃ»ts)
- **ArrÃªt automatique:** 60 secondes d'inactivitÃ© (suppression rapide)

### Configurations testÃ©es

| Configuration | Master | Workers | Workers prÃ©emptibles | Total vCPU | Limite respectÃ©e |
|---------------|--------|---------|----------------------|------------|------------------|
| 2 nÅ“uds       | 4 vCPU | 2Ã—4 vCPU| 2Ã—4 vCPU             | 12 vCPU    | âœ… < 32 vCPU     |
| 4 nÅ“uds       | 4 vCPU | 4Ã—4 vCPU| 4Ã—4 vCPU             | 20 vCPU    | âœ… < 32 vCPU     |
| 6 nÅ“uds       | 4 vCPU | 6Ã—4 vCPU| 6Ã—4 vCPU             | 28 vCPU    | âœ… < 32 vCPU     |

---

## ğŸ’° Optimisation des CoÃ»ts

### StratÃ©gies appliquÃ©es

1. âœ… **Machines prÃ©emptibles** - Ã‰conomie de 80%
2. âœ… **ArrÃªt automatique** - Pas de coÃ»ts inutiles
3. âœ… **Test progressif** - Validation avec 10% avant 100%
4. âœ… **Stockage rÃ©gional** - Pas de coÃ»ts multi-rÃ©gions
5. âœ… **Monitoring budget** - Alertes Ã  40â‚¬ par membre

### Estimation des coÃ»ts

| Ressource | QuantitÃ© | DurÃ©e estimÃ©e | CoÃ»t unitaire | CoÃ»t total |
|-----------|----------|---------------|---------------|------------|
| 2 workers prÃ©emptibles | 2 | 30 min | $0.04/h | ~$0.50 |
| 4 workers prÃ©emptibles | 4 | 20 min | $0.04/h | ~$0.80 |
| 6 workers prÃ©emptibles | 6 | 15 min | $0.04/h | ~$1.20 |
| Storage GCS | 2 GB | 1 mois | $0.020/GB | ~$0.05 |
| **TOTAL estimÃ©** | - | ~2h | - | **~10-15â‚¬** |

**Budget restant pour ajustements:** ~35-40â‚¬ par personne âœ…

---

## ğŸš€ Installation et ExÃ©cution

### PrÃ©requis

1. **Google Cloud SDK** installÃ©
   ```bash
   # Windows (PowerShell)
   # TÃ©lÃ©charger depuis: https://cloud.google.com/sdk/docs/install
   ```

2. **Compte Google Cloud** avec facturation activÃ©e

3. **Projet GCP** crÃ©Ã©

### âš™ï¸ Configuration Initiale

**IMPORTANT:** Avant toute exÃ©cution, modifiez la variable `PROJECT_ID` dans TOUS les scripts :
- `setup_gcp.sh`
- `data/download_data.sh`
- `scripts/create_cluster.sh`
- `scripts/run_experiments.sh`
- `scripts/cleanup.sh`

```bash
# Remplacer partout:
PROJECT_ID="votre-project-id"  # PAR EXEMPLE: PROJECT_ID="pagerank-m2-2025"
```

### ğŸ“‹ Ã‰tapes d'ExÃ©cution

#### Ã‰tape 1: Authentification et configuration GCP

```bash
# S'authentifier
gcloud auth login

# DÃ©finir le projet
gcloud config set project VOTRE-PROJECT-ID

# Configurer l'environnement
bash setup_gcp.sh
```

#### Ã‰tape 2: TÃ©lÃ©charger et prÃ©parer les donnÃ©es

```bash
cd data
bash download_data.sh
cd ..
```

âš ï¸ **Attention:** Le tÃ©lÃ©chargement complet fait ~1.8 GB. Le script crÃ©e automatiquement un Ã©chantillon de 10% pour les tests.

#### Ã‰tape 3: ExÃ©cuter les expÃ©riences

```bash
cd scripts
bash run_experiments.sh
```

Le script va :
1. CrÃ©er un cluster avec 2 workers
2. Tester RDD et DataFrame avec 10% des donnÃ©es
3. Demander confirmation pour tester avec 100%
4. Supprimer le cluster
5. RÃ©pÃ©ter pour 4 et 6 workers

#### Ã‰tape 4: Analyser les rÃ©sultats

Les logs sont sauvegardÃ©s dans `results/` :
- `rdd_2workers_10pct.log`
- `df_2workers_10pct.log`
- `rdd_2workers_full.log`
- etc.

Consultez aussi `results/performance_analysis.md` pour l'analyse dÃ©taillÃ©e.

#### Ã‰tape 5: Nettoyage

```bash
# Supprimer toutes les ressources
bash cleanup.sh
```

---

## ğŸ”§ Optimisations Techniques

### 1. Partitionnement Intelligent

**Objectif:** Ã‰viter le shuffle rÃ©seau (coÃ»teux en performance)

#### Dans RDD (`src/pagerank_rdd.py`)

```python
# Co-partitionnement des donnÃ©es
liens = liens_bruts.groupByKey() \
    .mapValues(list) \
    .partitionBy(200)  # â† Partitionnement par clÃ© (source)
    .cache()  # â† Cache pour Ã©viter recalcul

rangs = liens.map(lambda x: (x[0], 1.0)) \
    .partitionBy(200)  # â† MÃŠME partitionnement
```

**BÃ©nÃ©fice:** Lors du `.join()`, les donnÃ©es sont dÃ©jÃ  co-localisÃ©es â†’ pas de shuffle !

#### Dans DataFrame (`src/pagerank_dataframe.py`)

```python
# Repartitionnement et cache
df_liens = df_liens_bruts.groupBy("source") \
    .agg(collect_list("destination").alias("destinations")) \
    .repartition(200, "source")  # â† Partitionnement par source
    .cache()  # â† Cache

df_rangs = df_rangs.repartition(200, "source")  # â† MÃŠME clÃ© de partition
```

### 2. Cache StratÃ©gique

```python
# Cache des donnÃ©es qui NE CHANGENT PAS entre itÃ©rations
liens.cache()  # Le graphe de liens est constant
df_liens.cache()
```

**BÃ©nÃ©fice:** Ã‰vite de relire et reparser les donnÃ©es Ã  chaque itÃ©ration.

### 3. Configuration Spark Optimale

```python
spark = SparkSession.builder \
    .appName("PageRank") \
    .config("spark.sql.shuffle.partitions", "200") \
    .config("spark.sql.adaptive.enabled", "true")  # â† Optimisation adaptative
    .config("spark.executor.memory", "10g")  # â† MÃ©moire suffisante
    .config("spark.executor.cores", "3")  # â† ParallÃ©lisme
    .getOrCreate()
```

### 4. Algorithme PageRank

**ParamÃ¨tres:**
- **ItÃ©rations:** 10 (convergence gÃ©nÃ©ralement atteinte)
- **Damping factor:** 0.85 (standard acadÃ©mique)
- **Formule:** `PageRank(p) = 0.85 Ã— Î£(PR(in)/outlinks(in)) + 0.15`

---

## ğŸ“š Structure du Projet

```
page-rank/
â”œâ”€â”€ README.md                          # Ce fichier
â”œâ”€â”€ INSTRUCTIONS.md                    # Guide dÃ©taillÃ© pas-Ã -pas
â”œâ”€â”€ DEMARRAGE_RAPIDE.md                # Guide de dÃ©marrage rapide
â”œâ”€â”€ requirements.txt                   # DÃ©pendances Python
â”œâ”€â”€ setup_gcp.sh                       # Configuration Google Cloud
â”œâ”€â”€ .gitignore                         # Fichiers Ã  ignorer
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ download_data.sh               # TÃ©lÃ©chargement donnÃ©es Wikipedia
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ utils.py                       # Fonctions utilitaires
â”‚   â”œâ”€â”€ pagerank_rdd.py                # ImplÃ©mentation RDD
â”‚   â””â”€â”€ pagerank_dataframe.py          # ImplÃ©mentation DataFrame
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ create_cluster.sh              # CrÃ©ation cluster Dataproc
â”‚   â”œâ”€â”€ test_config_2workers.sh        # âœ¨ Test automatisÃ© 2 workers
â”‚   â”œâ”€â”€ test_config_4workers.sh        # âœ¨ Test automatisÃ© 4 workers
â”‚   â”œâ”€â”€ test_config_6workers.sh        # âœ¨ Test automatisÃ© 6 workers
â”‚   â”œâ”€â”€ compile_results.sh             # âœ¨ AgrÃ©gation et graphiques
â”‚   â”œâ”€â”€ generate_graphs.py             # âœ¨ GÃ©nÃ©ration graphiques Python
â”‚   â””â”€â”€ cleanup.sh                     # Nettoyage ressources
â”‚
â””â”€â”€ results/
    â”œâ”€â”€ config_2workers/               # RÃ©sultats configuration 2 workers
    â”œâ”€â”€ config_4workers/               # RÃ©sultats configuration 4 workers
    â”œâ”€â”€ config_6workers/               # RÃ©sultats configuration 6 workers
    â”œâ”€â”€ graphs/                        # âœ¨ Graphiques de comparaison PNG
    â”œâ”€â”€ performance_analysis.md        # Analyse dÃ©taillÃ©e
    â””â”€â”€ *.log                          # Logs d'exÃ©cution
```

### âœ¨ Nouveaux scripts automatisÃ©s

Les scripts `test_config_*workers.sh` effectuent **automatiquement** :
1. âœ… CrÃ©ation du cluster Dataproc avec la configuration spÃ©cifiÃ©e
2. âœ… Upload des scripts Python vers Cloud Storage
3. âœ… ExÃ©cution RDD sur 10% des donnÃ©es
4. âœ… ExÃ©cution DataFrame sur 10% des donnÃ©es
5. âœ… ExÃ©cution RDD sur 100% des donnÃ©es
6. âœ… ExÃ©cution DataFrame sur 100% des donnÃ©es
7. âœ… **Suppression immÃ©diate du cluster** (Ã©conomie de coÃ»ts!)
8. âœ… GÃ©nÃ©ration d'un fichier CSV de comparaison
9. âœ… Sauvegarde des logs dÃ©taillÃ©s

Le script `compile_results.sh` permet ensuite de :
- ğŸ“Š GÃ©nÃ©rer des graphiques de comparaison
- ğŸ“ˆ CrÃ©er un rÃ©capitulatif consolidÃ©
- ğŸ¯ Afficher les amÃ©liorations DataFrame vs RDD

---

## ğŸ” Observations et Analyses

### Partitionnement des DonnÃ©es

**StratÃ©gie utilisÃ©e:** Partitionnement par clÃ© (source) avec co-partitionnement

**RÃ©fÃ©rence:** Article NSDI sur l'optimisation du shuffle dans les systÃ¨mes distribuÃ©s

**RÃ©sultats:**
- âœ… Shuffle Ã©vitÃ© lors des joins
- âœ… DonnÃ©es co-localisÃ©es sur les mÃªmes workers
- âœ… Performances amÃ©liorÃ©es de [Ã€ COMPLÃ‰TER]%

### Convergence

- **CritÃ¨re de convergence:** Nombre fixe d'itÃ©rations (10)
- **Convergence observÃ©e:** [Ã€ COMPLÃ‰TER]
- **StabilitÃ© des rÃ©sultats:** [Ã€ COMPLÃ‰TER]

### ScalabilitÃ©

**Question:** Le speedup est-il linÃ©aire avec l'ajout de workers ?

**HypothÃ¨se:** Speedup sous-linÃ©aire dÃ» Ã  :
- Overhead de communication rÃ©seau
- Temps de setup du cluster
- Partie sÃ©quentielle (loi d'Amdahl)

**RÃ©sultats:** [Ã€ COMPLÃ‰TER APRÃˆS EXÃ‰CUTION]

---

## ğŸ“ Conclusions

### RDD vs DataFrame

**[Ã€ COMPLÃ‰TER APRÃˆS ANALYSE]**

Points attendus :
- Performance relative
- FacilitÃ© d'utilisation
- Optimisations du Catalyst (DataFrame)
- ContrÃ´le bas-niveau (RDD)

### Impact de la scalabilitÃ©

**[Ã€ COMPLÃ‰TER APRÃˆS ANALYSE]**

Points Ã  analyser :
- Speedup observÃ© vs thÃ©orique
- Bottlenecks identifiÃ©s
- Recommandations pour production

### Recommandations

**[Ã€ COMPLÃ‰TER APRÃˆS ANALYSE]**

---

## ğŸ“– RÃ©fÃ©rences

- **DonnÃ©es:** [DBpedia Wikilinks](https://databus.dbpedia.org/dbpedia/generic/wikilinks/2022.12.01/)
- **Article PageRank original:** Brin & Page, 1998
- **Apache Spark Documentation:** [spark.apache.org](https://spark.apache.org/docs/latest/)
- **Google Cloud Dataproc:** [cloud.google.com/dataproc](https://cloud.google.com/dataproc)

---

## âš ï¸ Notes Importantes

1. **Budget:** Surveillez rÃ©guliÃ¨rement vos coÃ»ts dans la console GCP
2. **Clusters:** Toujours supprimer les clusters aprÃ¨s utilisation
3. **DonnÃ©es:** Les donnÃ©es complÃ¨tes font 1.8 GB - testez avec 10% d'abord
4. **vCPU Limit:** Respect strict de la limite de 32 vCPU totaux
5. **RÃ©gion:** Utilisez `europe-west1` pour optimiser les coÃ»ts

---

## ğŸ†˜ DÃ©pannage

### Le cluster ne se crÃ©e pas

```bash
# VÃ©rifier les quotas
gcloud compute project-info describe --project=VOTRE-PROJECT-ID

# Augmenter les quotas si nÃ©cessaire (console GCP)
```

### Erreur "Permission denied"

```bash
# Activer les APIs nÃ©cessaires
gcloud services enable dataproc.googleapis.com
gcloud services enable storage.googleapis.com
```

### CoÃ»ts trop Ã©levÃ©s

```bash
# Lister tous les clusters actifs
gcloud dataproc clusters list --region=europe-west1

# Supprimer immÃ©diatement
gcloud dataproc clusters delete NOM-CLUSTER --region=europe-west1
```

---

## ğŸ“§ Contact

**Membres du groupe:**
- [NOM 1] - [email]
- [NOM 2] - [email]
- [NOM 3] - [email]

**Cours:** Large Scale Data Management  
**Enseignant:** Pascal Molli  
**AnnÃ©e:** 2025-2026

---

**Date de rendu:** [Ã€ COMPLÃ‰TER]  
**URL du dÃ©pÃ´t:** `https://github.com/yacinebellouche/page-rank`