# PageRank - Analyse de Performance PySpark

**Projet:** page-rank-479014  
**Dataset:** DBpedia WikiLinks (180M+ triples, 11GB non compressÃ©)  
**Date des tests:** 6 dÃ©cembre 2025  
**RÃ©gion GCP:** europe-west1

---

## ğŸ“Š RÃ©sumÃ© ExÃ©cutif

Ce document prÃ©sente les rÃ©sultats des tests de performance de l'algorithme PageRank sur un dataset complet de liens Wikipedia, exÃ©cutÃ© sur Google Cloud Dataproc avec diffÃ©rentes configurations de workers.

### Configurations TestÃ©es

| Configuration | Master   | Workers  | Total vCPU | RAM Totale | Type Machine  |
|---------------|----------|----------|------------|------------|---------------|
| **2 workers** | 1Ã—4 vCPU | 2Ã—4 vCPU | 12 vCPU    | ~48 GB     | e2-standard-4 |
| **4 workers** | 1Ã—4 vCPU | 4Ã—4 vCPU | 20 vCPU    | ~80 GB     | e2-standard-4 |
| **6 workers** | 1Ã—4 vCPU | 6Ã—4 vCPU | 28 vCPU    | ~112 GB    | e2-standard-4 |

### ParamÃ¨tres de l'Algorithme

- **ItÃ©rations:** 10
- **Damping factor:** 0.85
- **Partitions:** 200
- **MÃ©moire executor:** 12 GB
- **MÃ©moire driver:** 12 GB

---

## â±ï¸ Temps d'ExÃ©cution

### Tableau Comparatif

| Configuration | RDD (secondes) | RDD (minutes) | DataFrame (secondes) | DataFrame (minutes) | Gagnant  |
|---------------|----------------|---------------|----------------------|---------------------|----------|
| **2 workers** | 4401s          | 73 min        | 1955s                | 33 min              | DataFrame|
| **4 workers** | 2301s          | 38 min        | 1265s                | 21 min              | DataFrame|
| **6 workers** | 1634s          | 27 min        | 883s                 | 15 min              | DataFrame|

### Graphiques de Performance

![Comparaison RDD vs DataFrame](results/graphs/comparison_rdd_vs_dataframe.png)
*Figure 1: Comparaison des temps d'exÃ©cution RDD vs DataFrame*

![ScalabilitÃ©](results/graphs/scalability_speedup.png)
*Figure 2: Facteur d'accÃ©lÃ©ration selon le nombre de workers*

![AmÃ©lioration](results/graphs/improvement_percentage.png)
*Figure 3: Pourcentage d'amÃ©lioration DataFrame vs RDD*

![Ã‰volution](results/graphs/execution_time_evolution.png)
*Figure 4: Ã‰volution du temps d'exÃ©cution*

**Pour gÃ©nÃ©rer les graphiques:**
```bash
cd scripts
python generate_graphs.py
```

---

## ğŸš€ Analyse des Performances

### 1. AmÃ©lioration RDD vs DataFrame

| Configuration | Temps RDD | Temps DataFrame | AmÃ©lioration | Pourcentage            |
|---------------|-----------|-----------------|--------------|------------------------|
| **2 workers** | 4401s     | 1955s           | 2446s        | **55.57% plus rapide** |
| **4 workers** | 2301s     | 1265s           | 1036s        | **45.02% plus rapide** |
| **6 workers** | 1634s     | 883s            | 751s         | **45.96% plus rapide** |

**Conclusion:** DataFrame est systÃ©matiquement **45-55% plus rapide** que RDD grÃ¢ce Ã  l'optimiseur Catalyst et Tungsten execution engine.

### 2. ScalabilitÃ© (Speedup)

#### RDD - Facteur d'AccÃ©lÃ©ration

| Comparaison   | Speedup   | EfficacitÃ©        |
|---------------|-----------|-------------------|
| 2 â†’ 4 workers | **1.91x** | 95.5% (idÃ©al: 2x) |
| 4 â†’ 6 workers | **1.41x** | 94% (idÃ©al: 1.5x) |
| 2 â†’ 6 workers | **2.69x** | 90% (idÃ©al: 3x)   |

#### DataFrame - Facteur d'AccÃ©lÃ©ration

| Comparaison   | Speedup   | EfficacitÃ©        |
|---------------|-----------|-------------------|
| 2 â†’ 4 workers | **1.55x** | 77.5% (idÃ©al: 2x) |
| 4 â†’ 6 workers | **1.43x** | 95% (idÃ©al: 1.5x) |
| 2 â†’ 6 workers | **2.21x** | 74% (idÃ©al: 3x)   |

**Conclusion:** Excellente scalabilitÃ© pour les deux approches, proche de la scalabilitÃ© linÃ©aire idÃ©ale.

### 3. Rendements DÃ©croissants

L'amÃ©lioration des performances diminue avec l'ajout de workers :
- **2 â†’ 4 workers:** Gain important (1.9x pour RDD, 1.55x pour DataFrame)
- **4 â†’ 6 workers:** Gain modÃ©rÃ© (1.4x pour les deux)

Ceci est normal et dÃ» Ã  :
- Overhead de communication entre workers
- CoÃ»ts de shuffle des donnÃ©es
- Loi d'Amdahl (limites de la parallÃ©lisation)

---

## ğŸ¯ Centre de Wikipedia IdentifiÃ©

**RÃ©sultat pour toutes les configurations:**

```
Page avec le PageRank le plus Ã©levÃ©: Category:Living people
```

Ce rÃ©sultat est **cohÃ©rent et attendu** car cette catÃ©gorie regroupe toutes les personnes vivantes sur Wikipedia, crÃ©ant un hub massif de liens entrants.

### Top 20 Pages (6 workers, DataFrame)

| Rang | Page                          | PageRank Score         |   
|------|-------------------------------|------------------------|
| 1    | Category:Living people        | Score max              |
| 2-20 | Autres catÃ©gories principales | Scores Ã©levÃ©s          |

---

## ğŸ’° Analyse des CoÃ»ts

### Calcul des CoÃ»ts RÃ©els (Tarifs GCP europe-west1)

**Tarif e2-standard-4:** $0.134/heure par machine

#### Configuration 2 Workers (3 machines total: 1 master + 2 workers)

| ImplÃ©mentation | DurÃ©e              | Machines          | CoÃ»t/heure | CoÃ»t Total |
|----------------|--------------------|-------------------|------------|------------|
| RDD            | 73.35 min (1.22h)  | 3 Ã— e2-standard-4 | $0.402/h   | **$0.49**  |
| DataFrame      | 32.58 min (0.54h)  | 3 Ã— e2-standard-4 | $0.402/h   | **$0.22**  |
| **Total 2W**   | 105.93 min (1.77h) | - | - | **$0.71** |

#### Configuration 4 Workers (5 machines total: 1 master + 4 workers)

| ImplÃ©mentation | DurÃ©e             | Machines          | CoÃ»t/heure | CoÃ»t Total |
|----------------|-------------------|-------------------|------------|------------|
| RDD            | 38.35 min (0.64h) | 5 Ã— e2-standard-4 | $0.670/h   | **$0.43**  |
| DataFrame      | 21.08 min (0.35h) | 5 Ã— e2-standard-4 | $0.670/h   | **$0.23**  |
| **Total 4W**   | 59.43 min (0.99h) | - | - | **$0.66** |

#### Configuration 6 Workers (7 machines total: 1 master + 6 workers)

| ImplÃ©mentation | DurÃ©e             | Machines          | CoÃ»t/heure | CoÃ»t Total |
|----------------|-------------------|-------------------|------------|------------|
| RDD            | 27.23 min (0.45h) | 7 Ã— e2-standard-4 | $0.938/h   | **$0.42**  |
| DataFrame      | 14.72 min (0.25h) | 7 Ã— e2-standard-4 | $0.938/h   | **$0.23**  |
| **Total 6W**   | 41.95 min (0.70h) | - | - | **$0.66** |

### RÃ©sumÃ© des CoÃ»ts Totaux

| Configuration | CoÃ»t RDD | CoÃ»t DataFrame | **CoÃ»t Total** | Temps Total |
|---------------|----------|----------------|----------------|-------------|
| 2 workers     | $0.49    | $0.22          | **$0.71**      | 106 min     |
| 4 workers     | $0.43    | $0.23          | **$0.66**      | 59 min      |
| 6 workers     | $0.42    | $0.23          | **$0.66**      | 42 min      |

**CoÃ»t thÃ©orique des 3 tests:** $0.71 + $0.66 + $0.66 = **$2.03**

**CoÃ»t total rÃ©el du projet:** ~**$14 USD** (incluant tests multiples, dÃ©bogage, et ajustements de configuration)

---

## ğŸ”§ Configuration Technique

### Cluster Dataproc

```bash
gcloud dataproc clusters create pagerank-cluster-Xw \
    --region=europe-west1 \
    --zone=europe-west1-b \
    --master-machine-type=e2-standard-4 \
    --master-boot-disk-size=100 \
    --num-workers=X \
    --worker-machine-type=e2-standard-4 \
    --worker-boot-disk-size=100 \
    --image-version=2.1-debian11 \
    --max-idle=10m \
    --properties="spark:spark.executor.memory=12g,spark:spark.driver.memory=12g,spark:spark.executor.cores=3,spark:spark.sql.shuffle.partitions=200"
```

### ImplÃ©mentations TestÃ©es

#### RDD (Resilient Distributed Datasets)
- API bas niveau de Spark
- Transformations manuelles
- Pas d'optimisation automatique

#### DataFrame
- API haut niveau avec SQL
- Optimiseur Catalyst
- Adaptive Query Execution (AQE)
- Tungsten execution engine

---

## âœ… Validation des RÃ©sultats

### Tous les Tests RÃ©ussis

- âœ… **6/6 jobs terminÃ©s avec succÃ¨s**
- âœ… Centre de Wikipedia identique sur toutes les configs
- âœ… ScalabilitÃ© quasi-linÃ©aire dÃ©montrÃ©e
- âœ… CohÃ©rence des rÃ©sultats entre RDD et DataFrame

### ProblÃ¨mes Mineurs (Non-Bloquants)

- âš ï¸ Sauvegarde RDD Ã©chouÃ©e (fichier dÃ©jÃ  existant) - n'affecte pas les calculs
- âš ï¸ Quelques warnings YARN sur perte de replicas - job a continuÃ© avec succÃ¨s

---

## ğŸ“ Fichiers de RÃ©sultats

```
results/
â”œâ”€â”€ config_2workers/
â”‚   â”œâ”€â”€ rdd_full.log
â”‚   â”œâ”€â”€ df_full.log
â”‚   â”œâ”€â”€ summary.txt
â”‚   â””â”€â”€ comparison.csv
â”œâ”€â”€ config_4workers/
â”‚   â”œâ”€â”€ rdd_full.log
â”‚   â”œâ”€â”€ df_full.log
â”‚   â”œâ”€â”€ summary.txt
â”‚   â””â”€â”€ comparison.csv
â””â”€â”€ config_6workers/
    â”œâ”€â”€ rdd_full.log
    â”œâ”€â”€ df_full.log
    â”œâ”€â”€ summary.txt
    â””â”€â”€ comparison.csv
```

---

## ğŸ“ Conclusions Principales

1. **DataFrame >> RDD** - L'API DataFrame de Spark offre des performances nettement supÃ©rieures (~50% plus rapide)

2. **Excellente ScalabilitÃ©** - Le systÃ¨me scale presque linÃ©airement jusqu'Ã  6 workers

3. **RÃ©sultats CohÃ©rents** - Tous les tests identifient "Category:Living people" comme centre de Wikipedia

---

## ğŸ“š DÃ©tails d'ImplÃ©mentation

### Algorithme PageRank

```python
# Initialisation
rank(p) = 1.0 pour toutes les pages p

# ItÃ©rations (10 fois)
for i in 1 to 10:
    contributions(p) = rank(p) / outlinks(p)
    rank(p) = (1 - damping) + damping * Î£(contributions des liens entrants)
    
# OÃ¹ damping = 0.85
```

### OpÃ©rations RDD

```python
# 1. Charger et parser les donnÃ©es
links = sc.textFile(input).map(parse_ttl).filter(lambda x: x is not None)

# 2. Grouper par source avec partitionnement
links = links.groupByKey().mapValues(list).partitionBy(num_partitions).cache()

# 3. Initialiser les rangs
ranks = links.map(lambda x: (x[0], 1.0)).partitionBy(num_partitions)

# 4. ItÃ©rer
for iteration in range(10):
    contributions = links.join(ranks).flatMap(calculate_contributions)
    ranks = contributions.reduceByKey(add).mapValues(apply_damping).partitionBy(num_partitions)
```

### OpÃ©rations DataFrame

```python
# 1. CrÃ©er DataFrame
df_links = spark.createDataFrame(rdd.map(parse_ttl), ["source", "destination"])

# 2. Grouper et repartitionner
df_links = df_links.groupBy("source").agg(collect_list("destination")).repartition(num_partitions, "source").cache()

# 3. Initialiser rangs
df_ranks = df_links.select("source").distinct().withColumn("rank", lit(1.0)).repartition(num_partitions, "source")

# 4. ItÃ©rer (Catalyst optimise automatiquement)
for iteration in range(10):
    df_contributions = df_links.join(df_ranks, "source").select(explode(...))
    df_ranks = df_contributions.groupBy("destination").agg(sum("contribution")).select(apply_damping(...))
```

---

## ğŸ“ Structure du Projet

```
page-rank/
â”œâ”€â”€ README.md                    # Ce fichier
â”œâ”€â”€ setup_gcp.sh                 # Configuration GCP
â”œâ”€â”€ data/
â”‚   â””â”€â”€ download_simple.sh       # TÃ©lÃ©chargement donnÃ©es
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ pagerank_rdd.py          # ImplÃ©mentation RDD
â”‚   â”œâ”€â”€ pagerank_dataframe.py    # ImplÃ©mentation DataFrame
â”‚   â””â”€â”€ utils.py                 # Utilitaires partagÃ©s
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ test_config_2workers.sh  # Test 2 workers
â”‚   â”œâ”€â”€ test_config_4workers.sh  # Test 4 workers
â”‚   â”œâ”€â”€ test_config_6workers.sh  # Test 6 workers
â”‚   â””â”€â”€ cleanup.sh               # Nettoyage ressources
â””â”€â”€ results/
    â””â”€â”€ config_*workers/         # RÃ©sultats par configuration
```

---

##  Contributeurs

- **Bellouche Yacine**
- **Alhbbal Yazan**
- **Sellami Bachchar**

---

**GÃ©nÃ©rÃ© le:** 6 dÃ©cembre 2025  
**Projet GCP:** page-rank-479014
