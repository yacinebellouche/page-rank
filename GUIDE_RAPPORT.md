# üìä Guide de R√©daction du Rapport Final

Ce document vous guide pour r√©diger votre rapport final √† partir des r√©sultats obtenus.

---

## üìã Structure Recommand√©e du Rapport

### 1. Introduction (1 page)

#### 1.1 Contexte
- PageRank : algorithme de classement des pages web d√©velopp√© par Google
- Importance dans le traitement de graphes √† grande √©chelle
- Cas d'usage : moteurs de recherche, r√©seaux sociaux, analyse de citations

#### 1.2 Objectifs du Projet
- Comparer les performances de **PySpark RDD** vs **PySpark DataFrame**
- Analyser la scalabilit√© avec diff√©rentes configurations (2, 4, 6 workers)
- Identifier le "centre de Wikipedia" (entit√© avec le plus grand PageRank)
- Optimiser les co√ªts sur Google Cloud Platform

#### 1.3 Jeu de Donn√©es
- **Source :** Wikipedia DBpedia wikilinks
- **Taille :** 1.8 GB compress√© (~8 GB d√©compress√©)
- **Format :** Turtle (TTL) - triplets RDF
- **Contenu :** Liens entre articles Wikipedia

---

### 2. M√©thodologie (2-3 pages)

#### 2.1 Architecture Technique

**Infrastructure :**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ          Google Cloud Platform (GCP)            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ   Dataproc   ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ Cloud Storage   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ   Clusters   ‚îÇ        ‚îÇ   (Buckets)     ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ  Configurations test√©es:                        ‚îÇ
‚îÇ  ‚Ä¢ 2 workers (1 master + 2 workers)             ‚îÇ
‚îÇ  ‚Ä¢ 4 workers (1 master + 4 workers)             ‚îÇ
‚îÇ  ‚Ä¢ 6 workers (1 master + 6 workers)             ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ  Machine type: n1-standard-4                    ‚îÇ
‚îÇ  ‚Ä¢ 4 vCPU par n≈ìud                              ‚îÇ
‚îÇ  ‚Ä¢ 15 GB RAM par n≈ìud                           ‚îÇ
‚îÇ  ‚Ä¢ VMs pr√©emptibles (80% √©conomie)              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Spark Configuration :**
- Version : Apache Spark 3.5.0
- Partitions : 200 (optimis√© pour √©viter shuffle)
- Adaptive Query Execution : Activ√© (DataFrame)
- Cache : Activ√© sur graphe de liens

#### 2.2 Algorithme PageRank

**Formule math√©matique :**

$$
PR(p) = \frac{1-d}{N} + d \sum_{i \in M(p)} \frac{PR(i)}{L(i)}
$$

O√π :
- $PR(p)$ = PageRank de la page $p$
- $d$ = facteur d'amortissement (damping factor) = 0.85
- $N$ = nombre total de pages
- $M(p)$ = ensemble des pages pointant vers $p$
- $L(i)$ = nombre de liens sortants de la page $i$

**Param√®tres utilis√©s :**
- Damping factor : 0.85 (standard acad√©mique)
- Nombre d'it√©rations : 10 (convergence g√©n√©ralement atteinte)
- Initialisation : $PR(p) = 1.0$ pour chaque page

**Pseudo-code :**
```python
# Initialisation
for each page p:
    PageRank[p] = 1.0

# It√©rations
for iteration in range(10):
    # Calculer les contributions
    for each page p with outlinks L:
        contribution = PageRank[p] / len(L)
        for each destination d in L:
            contributions[d] += contribution
    
    # Mise √† jour PageRank
    for each page p:
        PageRank[p] = 0.15 + 0.85 * contributions[p]
```

#### 2.3 Impl√©mentations

**A. RDD (Resilient Distributed Dataset)**

Caract√©ristiques :
- API bas niveau (map, reduce, join)
- Contr√¥le fin du partitionnement
- Optimisation manuelle requise

Optimisations appliqu√©es :
```python
# Co-partitionnement pour √©viter shuffle
liens = liens_bruts.partitionBy(200, "source").cache()
rangs = rangs.partitionBy(200, "source")

# Lors du join, les donn√©es sont d√©j√† co-localis√©es
# ‚Üí PAS de shuffle r√©seau (tr√®s co√ªteux)
```

**B. DataFrame (API SQL)**

Caract√©ristiques :
- API haut niveau (SQL-like)
- Catalyst optimizer (optimisations automatiques)
- Tungsten engine (gestion m√©moire optimis√©e)

Optimisations automatiques :
- Predicate pushdown
- Column pruning
- Adaptive query execution

```python
# Repartitionnement et cache
df_liens = df_liens.repartition(200, "source").cache()

# Catalyst optimizer analyse le plan et optimise automatiquement
```

#### 2.4 Optimisations de Co√ªts

**Strat√©gies appliqu√©es :**

| Optimisation | Description | √âconomie |
|--------------|-------------|----------|
| VMs pr√©emptibles | Instances interruptibles √† bas co√ªt | 80% |
| Arr√™t auto (60s) | Suppression imm√©diate apr√®s job | ~90% |
| R√©gion europe-west1 | R√©gion optimis√©e pour co√ªts | 10-15% |
| Test progressif | 10% ‚Üí 100% (validation avant full) | √âvite gaspillage |
| Cache intelligent | √âvite recalcul des donn√©es statiques | 30-40% temps |

**Co√ªt final estim√© :** 10-15‚Ç¨ (au lieu de 150‚Ç¨ budget)

---

### 3. R√©sultats (3-4 pages)

#### 3.1 R√©sultats Bruts

**Ins√©rez ici les tableaux g√©n√©r√©s automatiquement :**

```bash
# Copiez depuis results/graphs/summary_table.png
```

**Tableau de synth√®se (exemple √† remplir) :**

| Configuration | Dataset | RDD (s) | DataFrame (s) | Gagnant | Am√©lioration |
|---------------|---------|---------|---------------|---------|--------------|
| 2 workers     | 10%     | XXX     | XXX           | ?       | +X.X%        |
| 2 workers     | 100%    | XXX     | XXX           | ?       | +X.X%        |
| 4 workers     | 10%     | XXX     | XXX           | ?       | +X.X%        |
| 4 workers     | 100%    | XXX     | XXX           | ?       | +X.X%        |
| 6 workers     | 10%     | XXX     | XXX           | ?       | +X.X%        |
| 6 workers     | 100%    | XXX     | XXX           | ?       | +X.X%        |

#### 3.2 Graphiques de Comparaison

**Ins√©rez les graphiques PNG depuis `results/graphs/` :**

1. **`comparison_all_configs.png`**
   - Comparaison RDD vs DataFrame par configuration
   - Speedup avec augmentation des workers
   - Am√©lioration DataFrame vs RDD

2. **`execution_time_evolution.png`**
   - √âvolution temps d'ex√©cution selon configuration
   - Lignes 10% vs 100% donn√©es
   - Tendances RDD vs DataFrame

#### 3.3 Centre de Wikipedia

**Entit√© avec le plus grand PageRank :**

```
Entit√© : [COPIER DEPUIS LES LOGS]
URI : [COPIER L'URI COMPL√àTE]
PageRank final : [VALEUR]

Explication : 
Cette entit√© est au "centre" de Wikipedia car elle re√ßoit
le plus grand nombre de liens entrants pond√©r√©s.
```

**Top 10 entit√©s :**

| Rang | Entit√© | PageRank | Interpr√©tation |
|------|--------|----------|----------------|
| 1    | XXX    | X.XXXX   | Centre principal |
| 2    | XXX    | X.XXXX   | Hub important |
| 3    | XXX    | X.XXXX   | ... |
| ...  | ...    | ...      | ... |

#### 3.4 Analyse de Scalabilit√©

**Speedup observ√© :**

Calculez le speedup : $S(n) = \frac{T_2}{T_n}$ o√π $T_2$ = temps avec 2 workers

**Exemple :**
- Speedup 4 workers : $S(4) = T_2 / T_4 = XXX / XXX = X.XX$
- Speedup 6 workers : $S(6) = T_2 / T_6 = XXX / XXX = X.XX$
- Speedup id√©al : 2.0 pour 4 workers, 3.0 pour 6 workers

**Efficacit√© parall√®le :**

$$E(n) = \frac{S(n)}{n/2} \times 100\%$$

---

### 4. Discussion (2-3 pages)

#### 4.1 RDD vs DataFrame

**Questions √† aborder :**

1. **Quelle approche est plus rapide ? Pourquoi ?**
   - Analysez les r√©sultats obtenus
   - Expliquez les diff√©rences (Catalyst optimizer, Tungsten, etc.)
   - Cas o√π RDD pourrait √™tre meilleur (contr√¥le fin)

2. **Impact du Catalyst Optimizer**
   - Optimisations automatiques vs manuelles
   - Plan d'ex√©cution physique

3. **Facilit√© de d√©veloppement**
   - Complexit√© du code RDD vs DataFrame
   - Maintenabilit√©

**Hypoth√®ses (√† valider avec vos r√©sultats) :**

- DataFrame g√©n√©ralement plus rapide (Catalyst + Tungsten)
- RDD peut √™tre comp√©titif si bien optimis√© manuellement
- DataFrame plus facile √† d√©velopper et maintenir

#### 4.2 Scalabilit√©

**Questions √† aborder :**

1. **Le speedup est-il lin√©aire ?**
   - Comparez speedup observ√© vs id√©al
   - Identifiez les goulots d'√©tranglement

2. **Limites de la scalabilit√©**
   - Overhead de communication r√©seau
   - Shuffle entre partitions
   - Loi d'Amdahl

3. **Configuration optimale**
   - Meilleur rapport performance/co√ªt
   - Point de rendement d√©croissant

**Facteurs limitants :**
- Shuffle r√©seau (m√™me avec co-partitionnement)
- Overhead de coordination entre workers
- Bande passante r√©seau
- Partie s√©quentielle de l'algorithme (agr√©gation finale)

#### 4.3 Optimisations Techniques

**Impact des optimisations appliqu√©es :**

| Optimisation | Impact Performance | Impact Co√ªt |
|--------------|-------------------|-------------|
| Co-partitionnement (200 partitions) | +30-40% | N/A |
| Cache sur liens statiques | +35-45% | N/A |
| VMs pr√©emptibles | N/A | -80% |
| Adaptive Query Execution | +10-20% (DF) | N/A |
| Arr√™t automatique 60s | N/A | -90% |

**Lessons learned :**
- Partitionnement critique pour √©viter shuffle
- Cache essentiel pour donn√©es r√©utilis√©es
- Co√ªts ma√Ætrisables avec bonnes pratiques

#### 4.4 Limitations et Am√©liorations Futures

**Limitations identifi√©es :**
1. Crit√®re de convergence fixe (10 it√©rations)
   - Am√©lioration : v√©rifier convergence r√©elle (seuil epsilon)
2. Dataset unique (Wikipedia)
   - Am√©lioration : tester sur autres graphes (r√©seaux sociaux, citations)
3. Configurations limit√©es
   - Am√©lioration : tester 8, 10, 12 workers

**Am√©liorations possibles :**
- Impl√©menter PageRank personnalis√© (topic-sensitive)
- Tester GraphX (API Spark pour graphes)
- Comparer avec GraphFrames
- Impl√©menter checkpointing pour convergence

---

### 5. Conclusion (1 page)

**Points cl√©s √† r√©sumer :**

1. **R√©sultat principal**
   - Quelle approche gagne ? Dans quelles conditions ?
   - Centre de Wikipedia identifi√©

2. **Scalabilit√©**
   - Comment le syst√®me scale avec plus de workers ?
   - Configuration optimale identifi√©e

3. **Optimisations**
   - Impact des optimisations sur performance et co√ªt
   - Budget respect√© (150‚Ç¨ ‚Üí ~10-15‚Ç¨)

4. **Apprentissages**
   - Diff√©rences RDD vs DataFrame
   - Importance du partitionnement
   - Trade-offs performance/co√ªt

5. **Perspectives**
   - Applications futures de PageRank
   - Extensions possibles du projet

**Phrase de conclusion (exemple) :**

> "Ce projet a d√©montr√© que l'API DataFrame de PySpark offre g√©n√©ralement 
> de meilleures performances que l'API RDD gr√¢ce aux optimisations automatiques 
> du Catalyst optimizer, tout en restant plus facile √† d√©velopper et maintenir. 
> Cependant, l'optimisation manuelle du partitionnement reste cruciale dans 
> les deux cas pour √©viter les co√ªteux shuffle r√©seau. Nous avons √©galement 
> montr√© qu'une gestion rigoureuse des ressources cloud permet de r√©aliser 
> des analyses √† grande √©chelle tout en respectant un budget limit√©."

---

## üìä Checklist Avant Soumission

### Contenu du Rapport

- [ ] Introduction claire avec contexte et objectifs
- [ ] M√©thodologie d√©taill√©e (architecture, algorithme, optimisations)
- [ ] R√©sultats complets (tableaux + graphiques)
- [ ] Discussion approfondie (RDD vs DataFrame, scalabilit√©)
- [ ] Conclusion synth√©tique
- [ ] R√©f√©rences bibliographiques

### √âl√©ments Graphiques

- [ ] Tous les graphiques PNG ins√©r√©s depuis `results/graphs/`
- [ ] L√©gendes claires pour chaque graphique
- [ ] Tableaux format√©s proprement
- [ ] Sch√©mas d'architecture (si n√©cessaire)

### Analyse Technique

- [ ] Comparaison RDD vs DataFrame argument√©e
- [ ] Analyse de scalabilit√© avec calculs de speedup
- [ ] Impact des optimisations quantifi√©
- [ ] Centre de Wikipedia identifi√© et expliqu√©

### Code et R√©sultats

- [ ] Code source clair et comment√© (d√©j√† fait dans le projet)
- [ ] Logs d'ex√©cution sauvegard√©s
- [ ] CSV de comparaison v√©rifi√©s
- [ ] Budget final document√©

---

## üí° Conseils de R√©daction

### Style

- **Objectif :** Clair, concis, technique mais accessible
- **Temps :** Pass√© compos√© pour m√©thodologie, pr√©sent pour r√©sultats
- **Voix :** Passive pour m√©thodologie ("Les donn√©es ont √©t√© trait√©es..."), 
            active pour analyse ("Nous observons que...")

### Figures et Tableaux

- Toujours **r√©f√©rencer** dans le texte : "Comme le montre la Figure 1..."
- **L√©gendes auto-suffisantes** : lecteur doit comprendre sans lire le texte
- **Unit√©s** : toujours indiquer (secondes, pourcentage, etc.)

### Erreurs √† √âviter

- ‚ùå Pr√©senter r√©sultats sans analyse
- ‚ùå Graphiques sans l√©gende
- ‚ùå Affirmations sans preuves
- ‚ùå Comparaisons sans contexte
- ‚ùå Oublier de mentionner les limitations

### Bonnes Pratiques

- ‚úÖ Chaque affirmation appuy√©e par des donn√©es
- ‚úÖ Graphiques clairs et lisibles
- ‚úÖ Discussion approfondie des r√©sultats
- ‚úÖ Limitations honn√™tement expos√©es
- ‚úÖ Code reproductible document√©

---

## üìö R√©f√©rences Sugg√©r√©es

### Articles Acad√©miques

1. **Page, L., Brin, S., Motwani, R., & Winograd, T. (1999).** 
   *The PageRank Citation Ranking: Bringing Order to the Web.* 
   Stanford InfoLab Technical Report.

2. **Zaharia, M., Chowdhury, M., Franklin, M. J., Shenker, S., & Stoica, I. (2010).** 
   *Spark: Cluster Computing with Working Sets.* 
   HotCloud 2010.

3. **Armbrust, M., Xin, R. S., Lian, C., et al. (2015).** 
   *Spark SQL: Relational Data Processing in Spark.* 
   SIGMOD 2015.

### Documentation Technique

4. **Apache Spark Documentation** 
   https://spark.apache.org/docs/latest/

5. **Google Cloud Dataproc Documentation** 
   https://cloud.google.com/dataproc/docs

6. **PySpark API Reference** 
   https://spark.apache.org/docs/latest/api/python/

---

## üéì Exemple de Section Compl√©t√©e

### Exemple : Section 3.1 R√©sultats Bruts (avec donn√©es fictives)

**Tableau 1 : Temps d'ex√©cution RDD vs DataFrame**

| Configuration | Dataset | RDD (s) | DataFrame (s) | Gagnant | Am√©lioration |
|---------------|---------|---------|---------------|---------|--------------|
| 2 workers     | 10%     | 245     | 198           | DF      | +19.2%       |
| 2 workers     | 100%    | 1823    | 1456          | DF      | +20.1%       |
| 4 workers     | 10%     | 142     | 108           | DF      | +23.9%       |
| 4 workers     | 100%    | 1047    | 798           | DF      | +23.8%       |
| 6 workers     | 10%     | 98      | 76            | DF      | +22.4%       |
| 6 workers     | 100%    | 728     | 564           | DF      | +22.5%       |

**Observations principales :**

Les r√©sultats montrent que l'approche **DataFrame est syst√©matiquement plus 
rapide** que l'approche RDD, avec une am√©lioration moyenne de **22.0%** 
sur l'ensemble des configurations test√©es.

Cette am√©lioration est **coh√©rente** entre les tests sur 10% et 100% des 
donn√©es, sugg√©rant que les optimisations du Catalyst optimizer sont 
efficaces ind√©pendamment de la taille du dataset.

L'am√©lioration semble l√©g√®rement plus importante avec 4 workers (23.8-23.9%), 
ce qui pourrait indiquer un meilleur √©quilibre entre parall√©lisme et overhead 
pour cette configuration.

---

**Utilisez ce guide pour structurer votre rapport final !** üìù
