# ğŸš€ QUICK START - PageRank Project

## âš¡ 30 Seconds Setup

```bash
# 1. Download data (once, ~15 min) - â­ Use optimized version
cd data && bash download_simple.sh && cd ..

# 2. Run ONE test (choose based on assignment)
cd scripts
bash test_config_2workers.sh    # Member 1
# OR
bash test_config_4workers.sh    # Member 2
# OR
bash test_config_6workers.sh    # Member 3

# 3. After ALL members finish, compile results
bash compile_results.sh
```

**DONE!** Results in `results/graphs/` + summary text.

---

## ğŸ“‹ What Each Script Does

### `test_config_2workers.sh` (and 4/6 workers)

**Fully automated:** Creates cluster â†’ Tests â†’ Deletes â†’ Results

```
1. âœ… Asks for PROJECT_ID (or uses env var)
2. âœ… Creates Dataproc cluster (preemptible VMs = 80% savings)
3. âœ… Uploads Python scripts to Cloud Storage
4. âœ… Runs RDD on 10% data
5. âœ… Runs DataFrame on 10% data
6. âœ… Runs RDD on 100% data
7. âœ… Runs DataFrame on 100% data
8. âœ… Deletes cluster IMMEDIATELY (saves 90% cost!)
9. âœ… Generates comparison CSV
10. âœ… Saves detailed logs
```

**Duration:** ~20-30 min  
**Cost:** ~3-5â‚¬ per config

### `compile_results.sh`

**Aggregates all results and generates graphs:**

```
1. âœ… Finds all result files (*.log, *.csv)
2. âœ… Generates comparison graphs (matplotlib)
3. âœ… Creates summary text file
4. âœ… Shows DataFrame vs RDD improvements
```

**Generates:**
- `results/graphs/comparison_all_configs.png`
- `results/graphs/execution_time_evolution.png`
- `results/graphs/summary_table.png`
- `results/summary_YYYYMMDD_HHMMSS.txt`

---

## ğŸ’° Costs

**Budget:** 150â‚¬ (50â‚¬ per member)  
**Actual cost:** ~12â‚¬ (4â‚¬ per member)  
**Savings:** 92%

| Config | Duration | Cost |
|--------|----------|------|
| 2 workers | ~20 min | ~3â‚¬ |
| 4 workers | ~25 min | ~4â‚¬ |
| 6 workers | ~30 min | ~5â‚¬ |

---

## ğŸ¯ Team Workflow (Recommended)

```
Member 1 (GCP account #1) â†’ bash test_config_2workers.sh
Member 2 (GCP account #2) â†’ bash test_config_4workers.sh
Member 3 (GCP account #3) â†’ bash test_config_6workers.sh

[All run in PARALLEL - 3x faster!]

Share results:
  - results/config_Xworkers/comparison.csv
  - results/config_Xworkers_*.log

One member compiles:
  â†’ bash compile_results.sh
```

**Total time:** ~40 min (instead of 2+ hours sequential!)

---

## ğŸ“– Documentation

**Read in order:**

1. **DEMARRAGE_RAPIDE.md** â† START HERE (French quick start)
2. **RECAPITULATIF.md** â† Full overview (French)
3. **CHECKLIST.md** â† Before launching
4. [Run tests]
5. **GUIDE_RAPPORT.md** â† Write final report (French)

**Detailed guides:**
- **INSTRUCTIONS.md** - Step-by-step guide (French)
- **OPTIMISATIONS.md** - Technical optimizations (French)
- **scripts/README.md** - Scripts usage guide

---

## ğŸ”§ Project Structure

```
page-rank/
â”œâ”€â”€ ğŸ“– Documentation (8 files)
â”‚   â”œâ”€â”€ README.md, DEMARRAGE_RAPIDE.md, INSTRUCTIONS.md
â”‚   â”œâ”€â”€ RECAPITULATIF.md, GUIDE_RAPPORT.md, CHECKLIST.md
â”‚   â””â”€â”€ OPTIMISATIONS.md, CONTENU.md
â”‚
â”œâ”€â”€ ğŸ’» Source Code (3 files)
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ utils.py
â”‚       â”œâ”€â”€ pagerank_rdd.py
â”‚       â””â”€â”€ pagerank_dataframe.py
â”‚
â”œâ”€â”€ ğŸ”§ Scripts (8 files)
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ test_config_2workers.sh âœ¨ NEW
â”‚       â”œâ”€â”€ test_config_4workers.sh âœ¨ NEW
â”‚       â”œâ”€â”€ test_config_6workers.sh âœ¨ NEW
â”‚       â”œâ”€â”€ compile_results.sh âœ¨ NEW
â”‚       â”œâ”€â”€ generate_graphs.py âœ¨ NEW
â”‚       â”œâ”€â”€ cleanup.sh
â”‚       â””â”€â”€ README.md
â”‚
â””â”€â”€ ğŸ“Š Results (generated)
    â””â”€â”€ results/
        â”œâ”€â”€ config_2workers/comparison.csv
        â”œâ”€â”€ config_4workers/comparison.csv
        â”œâ”€â”€ config_6workers/comparison.csv
        â”œâ”€â”€ graphs/*.png âœ¨ NEW
        â””â”€â”€ *.log, summary_*.txt
```

---

## âš™ï¸ PROJECT_ID Configuration

### Option 1: Environment Variable (Recommended)

```bash
export PROJECT_ID=your-gcp-project-id
bash test_config_2workers.sh  # Auto-uses PROJECT_ID
```

### Option 2: Interactive Prompt

```bash
bash test_config_2workers.sh
# Script asks: "Enter your PROJECT_ID:"
# Type: your-gcp-project-id
```

---

## ğŸ“ Key Features

### âœ… What Makes This Project Great

1. **Full Automation**
   - One command = complete results
   - No manual intervention during execution
   - Auto-cleanup (saves 90% cost!)

2. **Cost Optimization**
   - Preemptible VMs (80% savings)
   - Auto-shutdown after 60s (90% savings)
   - Budget: 150â‚¬ â†’ Actual: ~12â‚¬

3. **Performance Optimization**
   - Co-partitioning (avoids shuffle)
   - Strategic caching (avoids recomputation)
   - Optimized Spark configuration

4. **Team Workflow**
   - 3 members = 3 parallel tests
   - Time divided by 3
   - Easy result sharing (CSV files)

5. **Ready-to-Use Results**
   - High-quality graphs (PNG 300 DPI)
   - CSV tables
   - Text summary
   - Report writing guide

---

## ğŸ†˜ Troubleshooting

### "gcloud: command not found"

Install Google Cloud SDK:
```bash
# Check: https://cloud.google.com/sdk/install
```

### "Permission denied" when running scripts

Make scripts executable:
```bash
chmod +x scripts/*.sh
```

### Cluster creation fails

Check quotas:
```bash
gcloud compute project-info describe --project=PROJECT_ID
# Must have < 32 vCPU available
```

### Graphs not generating

Install Python packages:
```bash
python3 -m pip install matplotlib pandas numpy
```

---

## âœ… Pre-Launch Checklist

- [ ] Google Cloud SDK installed
- [ ] Authenticated to GCP (`gcloud auth login`)
- [ ] PROJECT_ID configured
- [ ] Data downloaded (`bash data/download_simple.sh`)
- [ ] Budget alert configured in GCP Console
- [ ] Scripts executable (`chmod +x` if needed)

---

## ğŸ“Š Expected Results

### Wikipedia Center

Entity with highest PageRank = "center" of Wikipedia.

**Likely candidates:**
- Very general concept (e.g., "Country", "City", "Person")
- Highly linked page (e.g., "United States", "France", "Europe")

### RDD vs DataFrame

**Hypotheses (validate with your results):**

- DataFrame faster thanks to Catalyst optimizer
- Expected improvement: +15-25%
- Consistent between 10% and 100% data
- Speedup sub-linear (overhead from network/coordination)

---

**Good luck! ğŸš€**

For detailed instructions in French, read **DEMARRAGE_RAPIDE.md**
