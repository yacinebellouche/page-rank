# üìñ INSTRUCTIONS COMPL√àTES - Projet PageRank

**Guide pas-√†-pas pour l'ex√©cution du projet**

Ce guide vous accompagne de A √† Z pour r√©aliser le projet PageRank sur Google Cloud Platform.

---

## üìã Table des Mati√®res

1. [Pr√©requis](#pr√©requis)
2. [Configuration Initiale](#configuration-initiale)
3. [Pr√©paration des Donn√©es](#pr√©paration-des-donn√©es)
4. [Ex√©cution des Exp√©riences](#ex√©cution-des-exp√©riences)
5. [Analyse des R√©sultats](#analyse-des-r√©sultats)
6. [Nettoyage](#nettoyage)
7. [D√©pannage](#d√©pannage)

---

## 1. Pr√©requis

### ‚úÖ Checklist Avant de Commencer

- [ ] Compte Google avec acc√®s √† Google Cloud Platform
- [ ] Carte bancaire pour activer la facturation (ou cr√©dits gratuits)
- [ ] Google Cloud SDK install√© sur votre machine
- [ ] Git install√© (pour cloner le d√©p√¥t)
- [ ] Bash/Shell disponible (Windows: Git Bash ou WSL)

### üì• Installation de Google Cloud SDK

#### Windows

```powershell
# T√©l√©charger depuis:
# https://cloud.google.com/sdk/docs/install

# Ou avec Chocolatey:
choco install gcloudsdk
```

#### Linux / macOS

```bash
# Suivre les instructions sur:
# https://cloud.google.com/sdk/docs/install
```

### ‚úÖ V√©rifier l'Installation

```bash
# V√©rifier que gcloud est install√©
gcloud --version

# Devrait afficher quelque chose comme:
# Google Cloud SDK 450.0.0
# ...
```

---

## 2. Configuration Initiale

### √âtape 2.1: Cr√©er un Projet Google Cloud

1. Allez sur https://console.cloud.google.com/
2. Cliquez sur "S√©lectionner un projet" ‚Üí "Nouveau projet"
3. Nommez votre projet (exemple: `pagerank-m2-2025`)
4. Notez l'**ID du projet** (diff√©rent du nom, ex: `pagerank-m2-2025-123456`)

### √âtape 2.2: Activer la Facturation

1. Dans la console GCP, allez dans "Facturation"
2. Associez votre projet √† un compte de facturation
3. ‚ö†Ô∏è **IMPORTANT:** Configurez une alerte de budget !

**Configurer une alerte de budget:**

```
Navigation: Facturation ‚Üí Budgets et alertes ‚Üí Cr√©er un budget

Param√®tres:
- Nom: "Budget PageRank"
- Montant: 50 EUR (ou USD) par membre
- Alertes: 50%, 80%, 100%
- Email: votre-email@etudiant.fr
```

### √âtape 2.3: Authentification

```bash
# S'authentifier avec votre compte Google
gcloud auth login

# Suivre les instructions dans le navigateur
```

### √âtape 2.4: Configurer le Projet

```bash
# D√©finir votre projet par d√©faut
gcloud config set project VOTRE-PROJECT-ID

# Exemple:
# gcloud config set project pagerank-m2-2025

# V√©rifier
gcloud config list
```

### √âtape 2.5: Modifier les Scripts

**CRUCIAL:** Avant d'ex√©cuter quoi que ce soit, vous DEVEZ modifier la variable `PROJECT_ID` dans **TOUS** les fichiers suivants :

```bash
# Fichiers √† modifier:
1. setup_gcp.sh
2. data/download_data.sh  
3. scripts/test_config_2workers.sh (ou 4/6 workers)
4. scripts/compile_results.sh
5. scripts/cleanup.sh# Dans chaque fichier, remplacer:
PROJECT_ID="votre-project-id"

# Par (exemple):
PROJECT_ID="pagerank-m2-2025"
```

**üí° Astuce:** Utilisez un √©diteur de texte avec fonction "Rechercher et Remplacer" pour modifier tous les fichiers d'un coup.

### √âtape 2.6: Ex√©cuter le Script de Configuration

```bash
# Rendre le script ex√©cutable
chmod +x setup_gcp.sh

# Ex√©cuter
bash setup_gcp.sh
```

Ce script va:
- ‚úÖ Activer les APIs n√©cessaires (Dataproc, Storage, Compute)
- ‚úÖ Cr√©er un bucket Google Cloud Storage
- ‚úÖ Cr√©er la structure de dossiers dans le bucket

**Sortie attendue:**
```
üöÄ Configuration du projet Google Cloud PageRank...
üì° Activation des APIs...
‚úÖ APIs activ√©es avec succ√®s
ü™£ Cr√©ation du bucket Google Cloud Storage...
‚úÖ Bucket cr√©√©: gs://pagerank-m2-2025-pagerank-data/
‚úÖ Configuration termin√©e avec succ√®s!
```

---

## 3. Pr√©paration des Donn√©es

### √âtape 3.1: T√©l√©charger les Donn√©es Wikipedia

```bash
# Aller dans le dossier data
cd data

# Rendre le script ex√©cutable
chmod +x download_data.sh

# Ex√©cuter le t√©l√©chargement
bash download_data.sh
```

**‚ö†Ô∏è Attention:**
- Le t√©l√©chargement fait ~1.8 GB
- Dur√©e: 5-30 minutes selon votre connexion
- Le script cr√©e automatiquement un √©chantillon de 10%

**Ce que fait le script:**
1. T√©l√©charge `wikilinks_lang=en.ttl.bz2` (1.8 GB)
2. D√©compresse le fichier
3. Cr√©e un √©chantillon de 10% pour les tests
4. Upload les deux fichiers vers Google Cloud Storage
5. (Optionnel) Supprime les fichiers locaux pour lib√©rer l'espace

**Sortie attendue:**
```
üì• T√©l√©chargement des donn√©es Wikipedia...
‚úÖ T√©l√©chargement termin√©
üì¶ D√©compression...
‚úÖ D√©compression termin√©e
‚úÇÔ∏è  Cr√©ation d'un √©chantillon de 10%...
‚úÖ √âchantillon cr√©√©
‚òÅÔ∏è  Upload vers Google Cloud Storage...
‚úÖ Upload termin√©
```

### √âtape 3.2: V√©rifier les Donn√©es

```bash
# V√©rifier que les fichiers sont bien dans GCS
gsutil ls -lh gs://VOTRE-PROJECT-ID-pagerank-data/data/

# Devrait afficher:
# wikilinks_10percent.ttl  (~XXX MB)
# wikilinks_full.ttl       (~XXX GB)
```

---

## 4. Ex√©cution des Exp√©riences

### √âtape 4.1: Pr√©parer l'Ex√©cution

```bash
# Retourner au dossier principal
cd ..

# Aller dans le dossier scripts
cd scripts

# Rendre les scripts ex√©cutables
chmod +x *.sh
```

### √âtape 4.2: Strat√©gie d'Ex√©cution Recommand√©e

**üéØ Approche Progressive (RECOMMAND√âE):**

```bash
# Phase 1: Test avec 10% sur petite configuration
# Objectif: Valider que tout fonctionne

# Phase 2: Si Phase 1 OK, tester les autres configurations avec 10%
# Objectif: Comparer les performances

# Phase 3: Si tout OK, tester avec 100% des donn√©es
# Objectif: R√©sultats finaux
```

### √âtape 4.3: Ex√©cution Automatis√©e (Toutes les Configurations)

```bash
# Chaque membre de l'√©quipe lance UNE configuration:
Membre 1: bash test_config_2workers.sh
Membre 2: bash test_config_4workers.sh
Membre 3: bash test_config_6workers.sh
```

**‚ö†Ô∏è Dur√©e par configuration:** 40-60 minutes

**Ce que fait chaque script:**

1. ‚úÖ Cr√©e le cluster Dataproc avec N workers
2. ‚úÖ Ex√©cute PageRank RDD avec 10% des donn√©es
3. ‚úÖ Ex√©cute PageRank DataFrame avec 10% des donn√©es
4. ‚úÖ Ex√©cute PageRank RDD avec 100% des donn√©es
5. ‚úÖ Ex√©cute PageRank DataFrame avec 100% des donn√©es
6. ‚úÖ Supprime le cluster automatiquement (max-idle: 60s)
7. ‚úÖ G√©n√®re results/config_Nworkers/comparison.csv

**Logs sauvegard√©s:**
- `results/config_2workers/rdd_10pct.log`
- `results/df_2workers_10pct.log`
- `results/rdd_4workers_10pct.log`
- `results/df_4workers_10pct.log`
- etc.

### √âtape 4.4: Ex√©cution Manuelle (Configuration par Configuration)

Si vous pr√©f√©rez contr√¥ler chaque √©tape:

```bash
# CONFIGURATION 1: 2 workers (D√âCONSEILL√â - Utiliser test_config_2workers.sh)
# Les scripts test_config_*workers.sh font ceci automatiquement

# Si vraiment vous voulez le faire manuellement:
# Cr√©er le cluster avec gcloud dataproc clusters create...
# (voir le contenu de test_config_2workers.sh pour la commande compl√®te)

# √âtape 2: Uploader les scripts
gsutil cp ../src/*.py gs://VOTRE-PROJECT-ID-pagerank-data/scripts/

# √âtape 3: Tester RDD (10%)
gcloud dataproc jobs submit pyspark \
  gs://VOTRE-PROJECT-ID-pagerank-data/scripts/pagerank_rdd.py \
  --cluster=pagerank-cluster-2workers \
  --region=europe-west1 \
  --py-files=gs://VOTRE-PROJECT-ID-pagerank-data/scripts/utils.py \
  -- gs://VOTRE-PROJECT-ID-pagerank-data/data/wikilinks_10percent.ttl 10

# √âtape 4: Tester DataFrame (10%)
gcloud dataproc jobs submit pyspark \
  gs://VOTRE-PROJECT-ID-pagerank-data/scripts/pagerank_dataframe.py \
  --cluster=pagerank-cluster-2workers \
  --region=europe-west1 \
  --py-files=gs://VOTRE-PROJECT-ID-pagerank-data/scripts/utils.py \
  -- gs://VOTRE-PROJECT-ID-pagerank-data/data/wikilinks_10percent.ttl 10

# √âtape 5: Supprimer le cluster
gcloud dataproc clusters delete pagerank-cluster --region=europe-west1

# R√©p√©ter pour 4 et 6 workers...
```

### √âtape 4.5: Suivre l'Ex√©cution

**Dans la Console GCP:**

1. Allez sur https://console.cloud.google.com/dataproc
2. S√©lectionnez votre projet
3. Cliquez sur "Clusters" ‚Üí Voir votre cluster
4. Cliquez sur "T√¢ches" ‚Üí Voir les jobs en cours

**En ligne de commande:**

```bash
# Lister les clusters actifs
gcloud dataproc clusters list --region=europe-west1

# Lister les jobs en cours
gcloud dataproc jobs list --region=europe-west1 --filter="status.state=RUNNING"

# Voir les logs d'un job sp√©cifique
gcloud dataproc jobs wait JOB-ID --region=europe-west1
```

---

## 5. Analyse des R√©sultats

### √âtape 5.1: R√©cup√©rer les Logs

Les logs sont d√©j√† sauvegard√©s localement dans `results/` pendant l'ex√©cution.

Pour t√©l√©charger les r√©sultats depuis GCS:

```bash
# T√©l√©charger tous les r√©sultats
gsutil -m cp -r gs://VOTRE-PROJECT-ID-pagerank-data/results/ ../results/gcs/
```

### √âtape 5.2: Extraire les Informations Cl√©s

#### Trouver le Centre de Wikipedia

```bash
# Dans les logs RDD (exemple)
grep "CENTRE DE WIKIPEDIA" ../results/rdd_6workers_full.log

# Dans les logs DataFrame
grep "CENTRE DE WIKIPEDIA" ../results/df_6workers_full.log
```

#### Extraire les Temps d'Ex√©cution

```bash
# Pour tous les logs
grep "Temps d'ex√©cution:" ../results/*.log

# Exemple de sortie:
# rdd_2workers_10pct.log:‚è±Ô∏è  Temps d'ex√©cution: 45.23 secondes
# df_2workers_10pct.log:‚è±Ô∏è  Temps d'ex√©cution: 38.67 secondes
```

### √âtape 5.3: Compl√©ter les Tableaux

**Dans README.md:**

Remplacez les `-` par vos r√©sultats r√©els.

**Dans results/performance_analysis.md:**

Remplissez tous les champs `[√Ä COMPL√âTER]` avec vos observations.

### √âtape 5.4: Cr√©er des Graphiques

**Outils recommand√©s:**
- Excel / Google Sheets
- Python (matplotlib/seaborn)
- R (ggplot2)

**Graphiques √† cr√©er:**
1. Temps d'ex√©cution vs Nombre de workers (RDD vs DF)
2. Speedup vs Configuration
3. Temps par phase (chargement, it√©rations, sauvegarde)

---

## 6. Nettoyage

### ‚ö†Ô∏è IMPORTANT: Toujours Nettoyer Apr√®s Usage!

```bash
# Ex√©cuter le script de nettoyage
cd scripts
bash cleanup.sh
```

**Le script va:**
1. ‚úÖ Supprimer tous les clusters Dataproc actifs
2. ‚ùì Demander si vous voulez supprimer le bucket GCS
3. ‚úÖ Annuler les jobs en cours
4. ‚úÖ Afficher un r√©sum√©

**V√©rifications manuelles recommand√©es:**

```bash
# V√©rifier qu'aucun cluster n'est actif
gcloud dataproc clusters list --region=europe-west1

# V√©rifier les co√ªts
# https://console.cloud.google.com/billing
```

---

## 7. D√©pannage

### Probl√®me 1: Le Cluster ne se Cr√©e Pas

**Erreur:** `Quota exceeded` ou `Insufficient resources`

**Solution:**

```bash
# V√©rifier vos quotas
gcloud compute project-info describe --project=VOTRE-PROJECT-ID

# Demander une augmentation de quota:
# https://console.cloud.google.com/iam-admin/quotas
```

### Probl√®me 2: Permission Denied

**Erreur:** `Permission denied` lors de l'ex√©cution

**Solution:**

```bash
# Activer les APIs
gcloud services enable dataproc.googleapis.com
gcloud services enable storage.googleapis.com
gcloud services enable compute.googleapis.com

# V√©rifier les r√¥les IAM
# Console ‚Üí IAM & Admin ‚Üí IAM
# Votre compte doit avoir les r√¥les:
# - Dataproc Editor
# - Storage Admin
```

### Probl√®me 3: Job √âchoue avec Out of Memory

**Erreur:** `OutOfMemoryError` dans les logs

**Solution:**

```bash
# Option 1: R√©duire les donn√©es (tester avec 10% d'abord)

# Option 2: Utiliser une configuration avec plus de workers
bash test_config_6workers.sh  # au lieu de test_config_2workers.sh

# Option 3: Si vraiment n√©cessaire, modifier les scripts test_config_*workers.sh
# pour augmenter la m√©moire:
--properties="spark:spark.executor.memory=12g,spark:spark.driver.memory=12g"
```

### Probl√®me 4: T√©l√©chargement des Donn√©es √âchoue

**Erreur:** Timeout ou connexion interrompue

**Solution:**

```bash
# Option 1: Utiliser wget avec reprise
wget -c -O wikilinks_full.ttl.bz2 [URL]

# Option 2: T√©l√©charger manuellement depuis:
# https://databus.dbpedia.org/dbpedia/generic/wikilinks/2022.12.01/

# Puis uploader vers GCS:
gsutil cp wikilinks_full.ttl.bz2 gs://VOTRE-BUCKET/data/
```

### Probl√®me 5: Co√ªts Trop √âlev√©s

**Sympt√¥me:** Budget d√©pass√©

**Actions imm√©diates:**

```bash
# 1. Supprimer TOUS les clusters
gcloud dataproc clusters list --region=europe-west1
gcloud dataproc clusters delete NOM-CLUSTER --region=europe-west1

# 2. V√©rifier les ressources actives
gcloud compute instances list

# 3. Consulter les co√ªts
# https://console.cloud.google.com/billing
```

**Pr√©vention:**
- Toujours tester avec 10% d'abord
- Utiliser des machines pr√©emptibles
- Activer les alertes de budget
- Supprimer les clusters apr√®s chaque utilisation

---

## üìä Checklist Finale

Avant de rendre le projet, v√©rifiez que vous avez:

### Code et Documentation

- [ ] Tous les scripts sont dans le d√©p√¥t Git
- [ ] README.md compl√©t√© avec vos noms et r√©sultats
- [ ] results/performance_analysis.md rempli
- [ ] Logs d'ex√©cution sauvegard√©s
- [ ] Graphiques cr√©√©s

### R√©sultats

- [ ] Centre de Wikipedia identifi√©
- [ ] Tableaux de performance remplis
- [ ] Comparaison RDD vs DataFrame effectu√©e
- [ ] Analyse de scalabilit√© compl√©t√©e
- [ ] Conclusions r√©dig√©es

### Nettoyage

- [ ] Tous les clusters supprim√©s
- [ ] Co√ªts v√©rifi√©s et dans le budget
- [ ] Bucket GCS nettoy√© (ou conserv√© si n√©cessaire)

### Rendu

- [ ] URL du d√©p√¥t Git pr√™te
- [ ] Noms des 3 membres du groupe indiqu√©s
- [ ] README.md professionnel et complet

---

## üí° Conseils Suppl√©mentaires

### Travail en √âquipe

- **Membre 1:** Configuration GCP et pr√©paration des donn√©es
- **Membre 2:** Ex√©cution des exp√©riences et collecte des logs
- **Membre 3:** Analyse des r√©sultats et r√©daction

### Timing Recommand√©

- **Jour 1:** Configuration et test avec 10% (2-3h)
- **Jour 2:** Exp√©riences compl√®tes (3-4h)
- **Jour 3:** Analyse et r√©daction (2-3h)

### Points d'Attention

1. ‚ö†Ô∏è **Budget:** Surveillez constamment vos co√ªts
2. ‚ö†Ô∏è **Quotas:** V√©rifiez la limite de 32 vCPU
3. ‚ö†Ô∏è **Temps:** Les jobs avec 100% peuvent prendre 30+ minutes
4. ‚ö†Ô∏è **Nettoyage:** TOUJOURS supprimer les ressources apr√®s usage

---

## üìß Support

En cas de probl√®me:

1. Consultez d'abord cette documentation
2. V√©rifiez la section [D√©pannage](#d√©pannage)
3. Consultez la documentation Google Cloud
4. Contactez l'enseignant: Pascal Molli

---

**Bon courage pour le projet! üöÄ**

**N'oubliez pas:** L'objectif est d'apprendre, pas de d√©penser tout le budget. Testez progressivement!
