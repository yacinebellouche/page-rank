#!/bin/bash

# ============================================================================
# SCRIPT AUTOMATIQUE - TEST AVEC 2 WORKERS
# ============================================================================
# Ce script exÃ©cute TOUT automatiquement pour la configuration 2 workers:
# 1. CrÃ©e le cluster
# 2. ExÃ©cute RDD et DataFrame sur 100% des donnÃ©es
# 3. GÃ©nÃ¨re les graphiques et comparaisons
# 4. Supprime le cluster IMMÃ‰DIATEMENT
# ============================================================================

# Configuration - MODIFIER ICI
PROJECT_ID="votre-projet-id"  #Changer PROJECT_ID
REGION="europe-west1"
CLUSTER_NAME="pagerank-cluster-2w"
BUCKET_NAME="${PROJECT_ID}-pagerank-data"
NUM_WORKERS=2

# Couleurs pour l'affichage
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

echo "============================================================================"
echo "ðŸš€ TEST AUTOMATIQUE - CONFIGURATION ${NUM_WORKERS} WORKERS"
echo "============================================================================"
echo ""

# VÃ©rifier que PROJECT_ID a Ã©tÃ© modifiÃ©
if [ "$PROJECT_ID" = "votre-project-id" ]; then
    echo -e "${RED}âŒ ERREUR: Vous devez modifier PROJECT_ID dans ce script !${NC}"
    exit 1
fi

# CrÃ©er dossier pour les rÃ©sultats
RESULTS_DIR="../results/config_${NUM_WORKERS}workers"
mkdir -p "$RESULTS_DIR"

# ============================================================================
# Ã‰TAPE 1: CRÃ‰ATION DU CLUSTER
# ============================================================================
echo -e "${BLUE}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo -e "${GREEN}ðŸ“‹ Ã‰TAPE 1/5: CrÃ©ation du cluster Dataproc${NC}"
echo -e "${BLUE}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo ""

TOTAL_VCPU=$((NUM_WORKERS * 4 + 4))
echo "Configuration:"
echo "  - Nom: $CLUSTER_NAME"
echo "  - Workers: $NUM_WORKERS"
echo "  - Total vCPU: $TOTAL_VCPU"
echo ""

# CrÃ©er le cluster avec arrÃªt immÃ©diat aprÃ¨s job
gcloud dataproc clusters create $CLUSTER_NAME \
    --region=$REGION \
    --zone=europe-west1-b \
    --master-machine-type=e2-standard-4 \
    --master-boot-disk-size=50GB \
    --num-workers=$NUM_WORKERS \
    --worker-machine-type=e2-standard-4 \
    --worker-boot-disk-size=50GB \
    --image-version=2.1-debian11 \
    --project=$PROJECT_ID \
    --bucket=$BUCKET_NAME \
    --max-idle=10m \
        --properties="spark:spark.executor.memory=12g,spark:spark.driver.memory=12g,spark:spark.executor.cores=3,spark:spark.sql.shuffle.partitions=200"

if [ $? -ne 0 ]; then
    echo -e "${RED}âŒ Ã‰chec de la crÃ©ation du cluster${NC}"
    exit 1
fi

echo -e "${GREEN}âœ… Cluster crÃ©Ã© avec succÃ¨s${NC}"
echo ""
sleep 10

# ============================================================================
# Ã‰TAPE 2: UPLOAD DES SCRIPTS
# ============================================================================
echo -e "${BLUE}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo -e "${GREEN}ðŸ“¤ Ã‰TAPE 2/5: Upload des scripts vers GCS${NC}"
echo -e "${BLUE}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo ""

gsutil cp ../src/*.py gs://$BUCKET_NAME/scripts/
echo -e "${GREEN}âœ… Scripts uploadÃ©s${NC}"
echo ""

# ============================================================================
# Ã‰TAPE 3: TESTS AVEC 100% DES DONNÃ‰ES
# ============================================================================
echo -e "${BLUE}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo -e "${GREEN}ðŸ“Š Ã‰TAPE 3/5: Tests avec 100% des donnÃ©es${NC}"
echo -e "${BLUE}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo ""

# Fichier .bz2 - PySpark dÃ©compresse automatiquement
DATA_FULL="gs://$BUCKET_NAME/data/wikilinks_full.ttl.bz2"
echo ""

# Test RDD - 100%
echo -e "${RED}ðŸ”´ PageRank RDD (100%)...${NC}"
START_TIME=$(date +%s)

gcloud dataproc jobs submit pyspark gs://$BUCKET_NAME/scripts/pagerank_rdd.py \
    --cluster=$CLUSTER_NAME \
    --region=$REGION \
    --py-files=gs://$BUCKET_NAME/scripts/utils.py \
    -- $DATA_FULL 10 \
    > "$RESULTS_DIR/rdd_full.log" 2>&1

END_TIME=$(date +%s)
RDD_FULL_TIME=$((END_TIME - START_TIME))
echo -e "${GREEN}âœ… RDD 100% terminÃ© en ${RDD_FULL_TIME}s${NC}"
echo ""

sleep 5

# Test DataFrame - 100%
echo -e "${BLUE}ðŸ”µ PageRank DataFrame (100%)...${NC}"
START_TIME=$(date +%s)

gcloud dataproc jobs submit pyspark gs://$BUCKET_NAME/scripts/pagerank_dataframe.py \
    --cluster=$CLUSTER_NAME \
    --region=$REGION \
    --py-files=gs://$BUCKET_NAME/scripts/utils.py \
    -- $DATA_FULL 10 \
    > "$RESULTS_DIR/df_full.log" 2>&1

END_TIME=$(date +%s)
DF_FULL_TIME=$((END_TIME - START_TIME))
echo -e "${GREEN}âœ… DataFrame 100% terminÃ© en ${DF_FULL_TIME}s${NC}"
echo ""

# ============================================================================
# Ã‰TAPE 4: GÃ‰NÃ‰RATION DES RÃ‰SULTATS ET GRAPHIQUES
# ============================================================================
echo -e "${BLUE}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo -e "${GREEN}ðŸ“ˆ Ã‰TAPE 4/5: GÃ©nÃ©ration des rÃ©sultats et comparaisons${NC}"
echo -e "${BLUE}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo ""

# Extraire le centre de Wikipedia
echo "Extraction du centre de Wikipedia..."
WIKI_CENTER_RDD=$(grep -A 1 "CENTRE DE WIKIPEDIA" "$RESULTS_DIR/rdd_full.log" | tail -1 || echo "N/A")
WIKI_CENTER_DF=$(grep -A 1 "CENTRE DE WIKIPEDIA" "$RESULTS_DIR/df_full.log" | tail -1 || echo "N/A")

# CrÃ©er le fichier de rÃ©sumÃ©
cat > "$RESULTS_DIR/summary.txt" << EOF
============================================================================
RÃ‰SULTATS - CONFIGURATION ${NUM_WORKERS} WORKERS
============================================================================
Date: $(date)
Projet: $PROJECT_ID
Cluster: $CLUSTER_NAME
Total vCPU: $TOTAL_VCPU

============================================================================
TEMPS D'EXÃ‰CUTION (100% DES DONNÃ‰ES)
============================================================================

  RDD:       ${RDD_FULL_TIME}s
  DataFrame: ${DF_FULL_TIME}s
  Gagnant:   $([ $RDD_FULL_TIME -lt $DF_FULL_TIME ] && echo "RDD" || echo "DataFrame")
  DiffÃ©rence: $((RDD_FULL_TIME > DF_FULL_TIME ? RDD_FULL_TIME - DF_FULL_TIME : DF_FULL_TIME - RDD_FULL_TIME))s

============================================================================
CENTRE DE WIKIPEDIA
============================================================================
RDD:       $WIKI_CENTER_RDD
DataFrame: $WIKI_CENTER_DF

============================================================================
COMPARAISON RDD vs DataFrame
============================================================================

Pourcentage d'amÃ©lioration:
  $([ $RDD_FULL_TIME -lt $DF_FULL_TIME ] && echo "RDD plus rapide de $(echo "scale=2; ($DF_FULL_TIME - $RDD_FULL_TIME) * 100 / $DF_FULL_TIME" | bc)%" || echo "DataFrame plus rapide de $(echo "scale=2; ($RDD_FULL_TIME - $DF_FULL_TIME) * 100 / $RDD_FULL_TIME" | bc)%")

============================================================================
FICHIERS GÃ‰NÃ‰RÃ‰S
============================================================================
  - rdd_full.log        : Log complet RDD 100%
  - df_full.log         : Log complet DataFrame 100%
  - summary.txt         : Ce fichier
  - comparison.csv      : DonnÃ©es pour graphiques

============================================================================
EOF

# CrÃ©er fichier CSV pour graphiques
cat > "$RESULTS_DIR/comparison.csv" << EOF
Type,Dataset,Time_seconds
RDD,100%,${RDD_FULL_TIME}
DataFrame,100%,${DF_FULL_TIME}
EOF

echo -e "${GREEN}âœ… Fichiers de rÃ©sultats crÃ©Ã©s:${NC}"
echo "  ðŸ“„ $RESULTS_DIR/summary.txt"
echo "  ðŸ“„ $RESULTS_DIR/comparison.csv"
echo "  ðŸ“„ $RESULTS_DIR/rdd_full.log"
echo "  ðŸ“„ $RESULTS_DIR/df_full.log"
echo ""

# Afficher le rÃ©sumÃ©
cat "$RESULTS_DIR/summary.txt"
echo ""

# ============================================================================
# SUPPRESSION IMMÃ‰DIATE DU CLUSTER
# ============================================================================
echo -e "${BLUE}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo -e "${GREEN}ðŸ§¹ Suppression IMMÃ‰DIATE du cluster${NC}"
echo -e "${BLUE}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo ""

echo -e "${YELLOW}ðŸ’° Suppression du cluster pour Ã©conomiser les coÃ»ts...${NC}"
gcloud dataproc clusters delete $CLUSTER_NAME \
    --region=$REGION \
    --quiet

if [ $? -eq 0 ]; then
    echo -e "${GREEN}âœ… Cluster supprimÃ© avec succÃ¨s${NC}"
else
    echo -e "${RED}âš ï¸  Erreur lors de la suppression - VÃ©rifiez manuellement!${NC}"
fi

echo ""
echo "============================================================================"
echo -e "${GREEN}âœ… TEST TERMINÃ‰ AVEC SUCCÃˆS - ${NUM_WORKERS} WORKERS${NC}"
echo "============================================================================"
echo ""
echo "ðŸ“Š RÃ©sultats disponibles dans: $RESULTS_DIR/"
echo ""
echo "ðŸŽ¯ Prochaines Ã©tapes:"
echo "  1. Consultez summary.txt pour les rÃ©sultats"
echo "  2. Utilisez comparison.csv pour crÃ©er des graphiques"
echo "  3. Lancez ./test_config_4workers.sh pour tester 4 workers"
echo ""
