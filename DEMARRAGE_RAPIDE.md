# ğŸš€ DÃ‰MARRAGE RAPIDE - Projet PageRank

**LISEZ CE FICHIER EN PREMIER !**

---

## âš¡ DÃ©marrage Rapide avec Scripts AutomatisÃ©s

### âœ¨ NOUVEAU : Scripts automatisÃ©s par configuration

Chaque membre de l'Ã©quipe peut lancer **un script unique** qui fait TOUT automatiquement :
- CrÃ©ation du cluster âœ…
- ExÃ©cution des tests âœ…  
- Suppression immÃ©diate du cluster âœ…
- GÃ©nÃ©ration des rÃ©sultats CSV âœ…

### Ã‰tape 1: Configuration Initiale (une fois)

```bash
# S'authentifier Ã  Google Cloud
gcloud auth login

# TÃ©lÃ©charger les donnÃ©es (une fois)
cd data
bash download_data.sh
cd ..

# ExÃ©cuter le setup
bash setup_gcp.sh
```

### Ã‰tape 2: Lancer UN test (choisir selon assignation)

**Chaque membre de l'Ã©quipe lance UN SEUL des scripts suivants :**

```bash
cd scripts

# Membre 1 - Configuration 2 workers (recommandÃ© pour dÃ©butant)
bash test_config_2workers.sh

# OU Membre 2 - Configuration 4 workers
bash test_config_4workers.sh

# OU Membre 3 - Configuration 6 workers
bash test_config_6workers.sh
```

**Le script vous demandera votre PROJECT_ID** (ou dÃ©finissez `export PROJECT_ID=votre-projet`)

**Ce qui se passe automatiquement :**
```
1. âœ… CrÃ©ation cluster (avec VMs prÃ©emptibles = 80% Ã©conomie)
2. âœ… Tests RDD et DataFrame sur 10% donnÃ©es
3. âœ… Tests RDD et DataFrame sur 100% donnÃ©es  
4. âœ… Suppression IMMÃ‰DIATE du cluster (Ã©conomie!)
5. âœ… GÃ©nÃ©ration CSV de comparaison
6. âœ… Sauvegarde logs dÃ©taillÃ©s
```

**DurÃ©e estimÃ©e :** 15-30 minutes

**CoÃ»t estimÃ© :** 3-5â‚¬ par configuration

### Ã‰tape 3: Partager les rÃ©sultats

AprÃ¨s l'exÃ©cution, partagez ces fichiers avec l'Ã©quipe :

```bash
# Fichier CSV (petit)
results/config_Xworkers/comparison.csv

# Log dÃ©taillÃ© (pour rÃ©fÃ©rence)
results/config_Xworkers_YYYYMMDD_HHMMSS.log
```

### Ã‰tape 4: Compilation finale (un seul membre)

Une fois que TOUS les membres ont partagÃ© leurs rÃ©sultats :

```bash
cd scripts
bash compile_results.sh
```

Cela gÃ©nÃ¨re :
- ğŸ“Š **Graphiques PNG** dans `results/graphs/`
- ğŸ“„ **RÃ©capitulatif texte** dans `results/summary_*.txt`
- ğŸ“ˆ **Comparaisons visuelles** RDD vs DataFrame

---

## ğŸ¯ Workflow en Ã‰quipe - RecommandÃ©

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 PHASE 1: Configuration (5 min)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Chaque membre:                                              â”‚
â”‚  1. gcloud auth login                                        â”‚
â”‚  2. cd data && bash download_data.sh                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            PHASE 2: ExÃ©cution ParallÃ¨le (20-30 min)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Membre 1: bash test_config_2workers.sh                      â”‚
â”‚  Membre 2: bash test_config_4workers.sh                      â”‚
â”‚  Membre 3: bash test_config_6workers.sh                      â”‚
â”‚                                                              â”‚
â”‚  âš¡ Les 3 tests tournent EN PARALLÃˆLE sur comptes sÃ©parÃ©s    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PHASE 3: Partage RÃ©sultats (5 min)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Chaque membre partage:                                      â”‚
â”‚  - results/config_Xworkers/comparison.csv                    â”‚
â”‚  - results/config_Xworkers_*.log                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           PHASE 4: Compilation Finale (5 min)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Un membre: bash compile_results.sh                          â”‚
â”‚  RÃ©sultat: Graphiques + tableaux consolidÃ©s                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Temps total : ~40 minutes** (au lieu de 2+ heures en sÃ©quentiel!)

---

## ğŸ“š Documentation ComplÃ¨te

Pour les instructions dÃ©taillÃ©es, consultez :

- **[INSTRUCTIONS.md](INSTRUCTIONS.md)** - Guide complet pas-Ã -pas
- **[README.md](README.md)** - Vue d'ensemble et rÃ©sultats

---

## âœ… Checklist Rapide

**Avant de commencer:**
- [ ] Compte Google Cloud crÃ©Ã©
- [ ] Facturation activÃ©e
- [ ] Alerte de budget configurÃ©e (50â‚¬ par membre)
- [ ] Google Cloud SDK installÃ©
- [ ] PROJECT_ID modifiÃ© dans TOUS les scripts

**Pendant l'exÃ©cution:**
- [ ] Tester avec 10% des donnÃ©es d'abord
- [ ] VÃ©rifier les coÃ»ts rÃ©guliÃ¨rement
- [ ] Sauvegarder les logs

**AprÃ¨s l'exÃ©cution:**
- [ ] Remplir les tableaux dans README.md
- [ ] ComplÃ©ter results/performance_analysis.md
- [ ] Supprimer les clusters (cleanup.sh)
- [ ] VÃ©rifier que tous les clusters sont supprimÃ©s

---

## ğŸ¯ Objectif du Projet

Comparer les performances de **PySpark RDD** vs **PySpark DataFrame** pour le calcul du PageRank sur les donnÃ©es Wikipedia (DBpedia).

### Configurations TestÃ©es

- 2 nÅ“uds (12 vCPU total)
- 4 nÅ“uds (20 vCPU total)  
- 6 nÅ“uds (28 vCPU total)

### RÃ©sultat Attendu

Identifier le **centre de Wikipedia** (page avec le plus grand PageRank).

---

## ğŸ’° Budget et CoÃ»ts

**Budget total:** 150â‚¬ (50â‚¬ par membre)

**CoÃ»t estimÃ© du projet:** 10-15â‚¬

**Optimisations appliquÃ©es:**
- âœ… Machines prÃ©emptibles (80% d'Ã©conomie)
- âœ… ArrÃªt automatique des clusters
- âœ… Test progressif (10% avant 100%)
- âœ… RÃ©gion optimale (europe-west1)

---

## ğŸ”§ Structure du Projet

```
page-rank/
â”œâ”€â”€ README.md                    # Vue d'ensemble et rÃ©sultats
â”œâ”€â”€ INSTRUCTIONS.md              # Guide dÃ©taillÃ©
â”œâ”€â”€ DEMARRAGE_RAPIDE.md         # Ce fichier
â”œâ”€â”€ requirements.txt             # DÃ©pendances Python
â”œâ”€â”€ setup_gcp.sh                # Configuration GCP initiale
â”œâ”€â”€ .gitignore                  # Fichiers Ã  ignorer
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ download_data.sh        # TÃ©lÃ©chargement donnÃ©es Wikipedia
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ utils.py                # Fonctions utilitaires
â”‚   â”œâ”€â”€ pagerank_rdd.py         # ImplÃ©mentation RDD
â”‚   â””â”€â”€ pagerank_dataframe.py   # ImplÃ©mentation DataFrame
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ create_cluster.sh       # CrÃ©ation cluster Dataproc
â”‚   â”œâ”€â”€ run_experiments.sh      # ExÃ©cution des expÃ©riences
â”‚   â””â”€â”€ cleanup.sh              # Nettoyage ressources
â”‚
â””â”€â”€ results/
    â”œâ”€â”€ performance_analysis.md # Analyse dÃ©taillÃ©e
    â””â”€â”€ *.log                   # Logs d'exÃ©cution
```

---

## ğŸ†˜ ProblÃ¨mes FrÃ©quents

### Le cluster ne se crÃ©e pas

```bash
# VÃ©rifier les quotas
gcloud compute project-info describe --project=VOTRE-PROJECT-ID
```

### Permission denied

```bash
# Activer les APIs
gcloud services enable dataproc.googleapis.com
gcloud services enable storage.googleapis.com
```

### Out of memory

```bash
# Augmenter le nombre de workers
bash create_cluster.sh 6  # au lieu de 2
```

### CoÃ»ts trop Ã©levÃ©s

```bash
# Supprimer TOUS les clusters immÃ©diatement
bash cleanup.sh
```

---

## ğŸ“Š Optimisations Techniques ImplÃ©mentÃ©es

### 1. Partitionnement Intelligent

**RDD:**
```python
liens = liens.partitionBy(200).cache()
rangs = rangs.partitionBy(200)
# â†’ Pas de shuffle lors du join!
```

**DataFrame:**
```python
df_liens = df_liens.repartition(200, "source").cache()
df_rangs = df_rangs.repartition(200, "source")
# â†’ Co-partitionnement optimisÃ©
```

### 2. Cache StratÃ©gique

```python
liens.cache()  # Le graphe ne change jamais
```

### 3. Configuration Spark Optimale

- Adaptive Query Execution activÃ©
- 200 partitions de shuffle
- MÃ©moire executor: 10 GB
- Serializer: Kryo

---

## ğŸ“ Points ClÃ©s du Projet

### Ce qui est demandÃ©

1. âœ… Comparaison RDD vs DataFrame
2. âœ… Tests sur 3 configurations (2/4/6 workers)
3. âœ… Ã‰viter le shuffle (partitionnement intelligent)
4. âœ… Identifier le centre de Wikipedia
5. âœ… Analyse de performance et scalabilitÃ©

### Ce qui est fourni

1. âœ… Code complet et optimisÃ©
2. âœ… Scripts d'automatisation
3. âœ… Documentation dÃ©taillÃ©e
4. âœ… Templates d'analyse
5. âœ… Optimisations de coÃ»ts

### Ce que vous devez faire

1. âœ… Modifier PROJECT_ID dans les scripts
2. âœ… ExÃ©cuter les expÃ©riences
3. âœ… Remplir les tableaux de rÃ©sultats
4. âœ… Analyser et conclure
5. âœ… Ajouter vos noms au README.md

---

## ğŸš€ Prochaines Ã‰tapes

1. **Lisez INSTRUCTIONS.md** pour le guide complet
2. **Modifiez PROJECT_ID** dans tous les scripts
3. **Configurez votre alerte de budget** (IMPORTANT!)
4. **Testez avec 10%** avant de lancer sur 100%
5. **Nettoyez toujours** aprÃ¨s utilisation

---

## ğŸ“§ Informations de Rendu

**Ã€ rendre:**
- URL du dÃ©pÃ´t GitHub/GitLab
- Noms des 3 membres du groupe

**Contenu attendu:**
- Code source complet
- README.md avec rÃ©sultats
- Centre de Wikipedia identifiÃ©
- Analyse comparative RDD vs DataFrame

---

**BON COURAGE! ğŸ‰**

N'oubliez pas: L'objectif est d'apprendre, pas de dÃ©penser tout le budget. Testez progressivement!
